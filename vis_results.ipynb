{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM6CZzW_CH0"
   },
   "source": [
    "# Stockformer Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5GFng7v7Eq0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# if not 'Informer2020' in sys.path:\n",
    "#     sys.path += ['Informer2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIjZdN5e_SWe"
   },
   "source": [
    "## Open log_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPdt-Kwc_RRZ"
   },
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils.ipynb_helpers import (\n",
    "    setting_from_args,\n",
    "    handle_gpu,\n",
    "    read_data,\n",
    ")\n",
    "import yaml\n",
    "from utils.stock_metrics import (\n",
    "    apply_threshold_metric,\n",
    "    PctProfitDirection,\n",
    "    PctProfitTanh,\n",
    "    LogPctProfitDirection,\n",
    "    LogPctProfitTanhV1,\n",
    "    pct_direction,\n",
    ")\n",
    "from utils.results_analysis import open_results, get_tuned_metrics\n",
    "\n",
    "# log_dir = \"bbtest_logs/2023_01_25_11_46_44_stockformer_sl16_ei9_dm512_nh16_el4_ebtime2vec_app/version_45\"\n",
    "# log_dir = \"bbtest_logs/2023_01_29_12_38_22_stockformer_sl16_ei9_dm512_nh16_el4_ebtime2vec_app/version_45\"\n",
    "# log_dir = \"bbtest_logs/2023_01_29_17_53_13_stockformer_sl16_ei12_dm512_nh16_el4_ebtime2vec_app/version_6\"\n",
    "# log_dir = \"bbtest_logs/2023_01_31_14_29_23_stockformer_sl16_ei10_dm512_nh16_el4_ebtime2vec_add/version_5\"\n",
    "log_dir = \"lightning_logs/2023_01_31_17_58_24_stockformer_sl16_ei9_dm512_nh16_el4_ebtime2vec_add/version_0\"\n",
    "with open(os.path.join(log_dir, \"hparams.yaml\"), \"r\") as file:\n",
    "    args = dotdict(yaml.load(file, Loader=yaml.FullLoader))\n",
    "\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_data(os.path.join(args.root_path,args.data_path))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNhEP_7sAgqC"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMRk8VkQ2Iko",
    "outputId": "bbf3cd10-7294-472d-e330-21e00f20963a"
   },
   "outputs": [],
   "source": [
    "tpd_dict = open_results(log_dir, args, df)\n",
    "\n",
    "print(\"Open true/pred data for:\", list(tpd_dict.keys()))\n",
    "\n",
    "# [samples, pred_len, dimensions]\n",
    "print(\n",
    "    tpd_dict[\"train\"][\"trues\"].shape, tpd_dict[\"val\"][\"trues\"].shape, tpd_dict[\"test\"][\"trues\"].shape, \"\\n\\n\"\n",
    ")\n",
    "\n",
    "for data_group in tpd_dict:\n",
    "    trues = tpd_dict[data_group][\"trues\"]\n",
    "    preds = tpd_dict[data_group][\"preds\"]\n",
    "    dates = tpd_dict[data_group][\"dates\"]\n",
    "    print(\n",
    "        f\"{data_group}\\ttrues.shape: {trues.shape}, preds.shape: {preds.shape}, dates.shape: {dates.shape}\"\n",
    "    )\n",
    "\n",
    "    MSE = np.square(np.subtract(trues, preds)).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print(\"against preds\", MSE, RMSE)\n",
    "\n",
    "    MSE = np.square(np.subtract(trues, np.zeros(preds.shape))).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print(\"against 0s\", MSE, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "kyPuOPGAAjl3",
    "outputId": "8554f6f8-c13a-43e1-b04b-5f27823445d0"
   },
   "outputs": [],
   "source": [
    "for data_group in tpd_dict:\n",
    "    true = tpd_dict[data_group][\"trues\"]\n",
    "    pred = tpd_dict[data_group][\"preds\"]\n",
    "    date = tpd_dict[data_group][\"dates\"]\n",
    "\n",
    "    if \"stock\" in args.loss:\n",
    "        # pred = np.tanh(pred)\n",
    "        true = (true / np.linalg.norm(true))*np.linalg.norm(pred)\n",
    "\n",
    "    plt.figure(num=data_group, figsize=(16, 4))\n",
    "    plt.title(data_group)\n",
    "    plt.plot(date, true, label=\"GroundTruth\", linestyle=\"\", marker=\".\", markersize=4)\n",
    "    plt.plot(date, pred, label=\"Prediction\", linestyle=\"\", marker=\".\", markersize=4)\n",
    "    plt.plot(date, np.zeros(date.shape), color=\"red\")\n",
    "\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(num=data_group, figsize=(16, 4))\n",
    "    plt.title(\"Diff histogram\")\n",
    "    plt.hist(\n",
    "        [np.abs(true), np.abs(true - pred)], bins=60, label=[\"Diff 0\", \"Diff Pred\"]\n",
    "    )\n",
    "    plt.xlabel(\"Diff Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic back-test based on buying in predicted direction if prediction is above a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_thresh, best_thresh_metrics, zero_thresh_metrics = get_tuned_metrics(args, tpd_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(4,1, sharex=True, figsize=(16, 8))\n",
    "\n",
    "for data_group in [\"val\", \"test\"]: #tpd_dict:\n",
    "    true = tpd_dict[data_group][\"trues\"]\n",
    "    pred = tpd_dict[data_group][\"preds\"]\n",
    "    date = tpd_dict[data_group][\"dates\"]\n",
    "\n",
    "    # if data_group == \"train\":\n",
    "    #     true = true[:1000]\n",
    "    #     pred = pred[:1000]\n",
    "    #     date = date[:1000]\n",
    "\n",
    "\n",
    "    # Filter by best_thresh. Note in log scale\n",
    "    pred_f, true_f = apply_threshold_metric(pred, true, best_thresh)\n",
    "    date_f = date[np.abs(pred) >= best_thresh]\n",
    "    df_f = df.loc[date[np.abs(pred) >= best_thresh]]\n",
    "\n",
    "    if \"lpp\" in args.loss:\n",
    "        metric = LogPctProfitDirection\n",
    "        metric_name = \"pct_profit_dir\"\n",
    "    elif \"tanh\" in args.loss:\n",
    "        metric = LogPctProfitTanhV1\n",
    "        metric_name = \"pct_profit_tanh\"\n",
    "    elif \"mse\" in args.loss:\n",
    "        metric = LogPctProfitDirection\n",
    "        metric_name = \"pct_profit_dir\"\n",
    "    elif \"mae\" in args.loss:\n",
    "        metric = LogPctProfitDirection\n",
    "        metric_name = \"pct_profit_dir\"\n",
    "\n",
    "    axs[0].plot(date_f, metric.accumulate(pred_f, true_f, short_filter=None), label=data_group)\n",
    "    axs[0].set_ylabel(metric_name)\n",
    "    axs[0].set_title(metric_name)\n",
    "    axs[0].grid(axis = 'y')\n",
    "\n",
    "    axs[1].plot(date_f[pred_f > 0], metric.accumulate(pred_f, true_f, short_filter=\"ns\"))#, label=data_group)\n",
    "    axs[1].set_ylabel(f\"{metric_name}_nshort\")\n",
    "    axs[1].set_title(f\"{metric_name}_nshort\")\n",
    "    axs[1].grid(axis = 'y')\n",
    "\n",
    "    axs[2].plot(date_f[pred_f < 0], metric.accumulate(pred_f, true_f, short_filter=\"os\"))#, label=data_group)\n",
    "    axs[2].set_ylabel(f\"{metric_name}_oshort\")\n",
    "    axs[2].set_title(f\"{metric_name}_oshort\")\n",
    "    axs[2].grid(axis = 'y')\n",
    "\n",
    "    axs[3].plot(date_f, np.exp(np.cumsum(true_f)), label=\"Market\")\n",
    "    # axs[3].set_ylabel(\"Market\")\n",
    "    axs[3].set_title(\"Market\")\n",
    "    axs[3].grid(axis = 'y')\n",
    "\n",
    "fig.legend()\n",
    "fig.suptitle(\"Cumulative metrics overtime\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iflTTl0quCoK",
    "outputId": "3708fc91-517e-4c83-e133-059381bde271"
   },
   "outputs": [],
   "source": [
    "# args.output_attention = True\n",
    "\n",
    "# exp = Exp(args)\n",
    "\n",
    "# model = exp.model\n",
    "\n",
    "# path = os.path.join(args.checkpoints, setting, \"checkpoint.pth\")\n",
    "\n",
    "# print(model.load_state_dict(torch.load(path)))\n",
    "\n",
    "# df = pd.read_csv(os.path.join(args.root_path, args.data_path))\n",
    "# df[args.cols].head()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# from data_provider.data_loader import Dataset_Custom\n",
    "# from torch.utils.data import DataLoader\n",
    "\n",
    "# Data = Dataset_Custom\n",
    "# timeenc = 0 if args.t_embed != \"timeF\" else 1\n",
    "# data_group = \"test\"\n",
    "# shuffle_data_group = False\n",
    "# drop_last = True\n",
    "# batch_size = 1\n",
    "# data_set = Data(args, data_group=data_group)\n",
    "\n",
    "# data_loader = DataLoader(\n",
    "#     data_set,\n",
    "#     batch_size=batch_size,\n",
    "#     shuffle=shuffle_data_group,\n",
    "#     num_workers=args.num_workers,\n",
    "#     drop_last=drop_last,\n",
    "# )\n",
    "\n",
    "\n",
    "# idx = 0\n",
    "# for i, (batch_x, batch_y, batch_x_mark, batch_y_mark, ds_index) in enumerate(\n",
    "#     data_loader\n",
    "# ):\n",
    "#     if i != idx:\n",
    "#         continue\n",
    "#     batch_x = batch_x.float().to(exp.device)\n",
    "#     batch_y = batch_y.float()\n",
    "\n",
    "#     batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "#     batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "#     dec_inp = torch.zeros_like(batch_y[:, -args.pred_len :, :]).float()\n",
    "#     dec_inp = (\n",
    "#         torch.cat([batch_y[:, : args.label_len, :], dec_inp], dim=1)\n",
    "#         .float()\n",
    "#         .to(exp.device)\n",
    "#     )\n",
    "\n",
    "#     outputs, attn = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "\n",
    "# print(attn[0].shape, attn[1].shape)  # , attn[2].shape\n",
    "\n",
    "\n",
    "# layers = [0, 1]\n",
    "# distil = \"Distil\" if args.distil else \"NoDistil\"\n",
    "# for layer in layers:\n",
    "#     print(\"\\n\\n==========================\")\n",
    "#     print(\"Showing attention layer\", layer)\n",
    "#     print(\"==========================\\n\\n\")\n",
    "#     for h in range(0, args.n_heads):\n",
    "#         plt.figure(figsize=[10, 8])\n",
    "#         plt.title(f\"Informer, {distil}, attn:{args.attn} layer:{layer} head:{h}\")\n",
    "#         A = attn[layer][0, h].detach().cpu().numpy()\n",
    "#         ax = sns.heatmap(A, vmin=0, vmax=A.max() + 0.01)\n",
    "#         plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import pytorch_lightning as pl\n",
    "# from exp.exp_timeseries import ExpTimeseries\n",
    "# from data_provider.data_module import CustomDataModule\n",
    "\n",
    "# trainer = pl.Trainer(accelerator=\"gpu\",devices=1)#, log_dir=os.path.abspath(log_dir))\n",
    "\n",
    "# exp = ExpTimeseries.load_from_checkpoint(\n",
    "#     os.path.join(log_dir, \"checkpoints/checkpoint.ckpt\"), config=args\n",
    "# )\n",
    "# data_module = CustomDataModule(args, 0)\n",
    "\n",
    "# # Test Model\n",
    "# # t = trainer.test(exp, data_module)\n",
    "\n",
    "# # # Predict and Save Results\n",
    "# results = trainer.predict(exp, data_module)\n",
    "# results"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "51980e48e269f7c05efac26b22569386591d7f1d45336266d53ed7fc3ab7efc6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
