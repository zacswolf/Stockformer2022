{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5IM6CZzW_CH0"
   },
   "source": [
    "# Stockformer Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b5GFng7v7Eq0"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# if not 'Informer2020' in sys.path:\n",
    "#     sys.path += ['Informer2020']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rIjZdN5e_SWe"
   },
   "source": [
    "## Experiments: Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RPdt-Kwc_RRZ"
   },
   "outputs": [],
   "source": [
    "from utils.tools import dotdict\n",
    "from exp.exp_informer import Exp_Informer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pprint import pprint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from utils.ipynb_helpers import (\n",
    "    args_from_setting,\n",
    "    setting_from_args,\n",
    "    handle_gpu,\n",
    "    read_data,\n",
    ")\n",
    "from utils.stock_metrics import (\n",
    "    apply_threshold_metric,\n",
    "    PctProfitDirection,\n",
    "    PctProfitTanh,\n",
    "    PctDirection\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6mx2dnwY9dWi"
   },
   "outputs": [],
   "source": [
    "args = dotdict()\n",
    "args.des = \"full_1h\"\n",
    "\n",
    "args.model = \"stockformer\"  # 'stockformer'\n",
    "\n",
    "args.data = \"custom\"  # data\n",
    "args.checkpoints = \"./checkpoints\"  # location of model checkpoints\n",
    "args.root_path = \"./data/stock/\"  # root path of data file\n",
    "\n",
    "args.data_path = \"full_1h.csv\"  # data file\n",
    "args.freq = \"h\"  # freq for time features encoding, options:[s:secondly, t:minutely, h:hourly, d:daily, b:business days, w:weekly, m:monthly], you can also use more detailed freq like 15min or 3h\n",
    "\n",
    "args.features = \"MS\"  # forecasting task, options:[M, S, MS]; M:multivariate predict multivariate, S:univariate predict univariate, MS:multivariate predict univariate\n",
    "args.target = \"XOM_pctchange\"  # target feature in S or MS task\n",
    "\n",
    "\n",
    "args.seq_len = 16  # input sequence length of Informer encoder\n",
    "args.label_len = 1  # start token length of Informer decoder\n",
    "args.pred_len = 1  # prediction sequence length\n",
    "\n",
    "# [\"XOM_close\", \"BP_close\", \"CVX_close\", \"WTI_close\"]\n",
    "# [\"XOM_open\", \"XOM_high\", \"XOM_low\", \"XOM_close\", \"XOM_volume\", \"XOM_pctchange\", \"XOM_shortsma\"]\n",
    "args.cols = [\n",
    "    \"XOM_pctchange\",  # \"XOM_open\", \"XOM_close\", , \"XOM_shortsma\",\n",
    "    \"CVX_pctchange\",\n",
    "    \"COP_pctchange\",\n",
    "    \"BP_pctchange\",\n",
    "    \"PBR_pctchange\",\n",
    "    \"WTI_pctchange\",\n",
    "    \"EOG_pctchange\",\n",
    "    \"ENB_pctchange\",\n",
    "    \"SLB_pctchange\",\n",
    "]  #'C:USDSAR_pctchange'\n",
    "\n",
    "args.enc_in = len(args.cols)  # encoder input size\n",
    "# args.dec_in = len(args.cols) # decoder input size # TODO: Remove\n",
    "args.c_out = 1 if args.features in [\"S\", \"MS\"] else args.dec_in  # output size\n",
    "\n",
    "\n",
    "args.d_model = 128  # dimension of model; also the dimension of the token embeddings\n",
    "args.n_heads = 8  # num of attention heads\n",
    "args.e_layers = 12  # num of encoder layers\n",
    "# args.d_layers = 4 # num of decoder layers # TODO: Remove\n",
    "args.d_ff = 2048  # dimension of fcn in model\n",
    "args.dropout = 0.05  # dropout\n",
    "args.embed = None  # time features encoding, options:[timeF, fixed, learned, None]\n",
    "args.activation = \"gelu\"  # activation\n",
    "\n",
    "args.attn = \"full\"  # attention used in encoder, options:[prob, full]\n",
    "args.factor = 5  # probsparse attn factor; doesn't matter unless args.attn==prob\n",
    "args.distil = False  # whether to use distilling in encoder\n",
    "args.output_attention = False  # whether to output attention in encoder\n",
    "args.mix = False  # whether to use mixed attention\n",
    "args.padding = 0  # TODO: Remove\n",
    "\n",
    "args.batch_size = 256  # 64\n",
    "args.learning_rate = 0.00001\n",
    "args.loss = \"stock_tanh\"  # What loss function to use: [\"mse\", \"stock_lpp\", \"stock_lppns\", \"stock_tanh\"]\n",
    "args.lradj = None  # What learning rate scheduler to use: [\"type3\", None, \"type1\"]\n",
    "args.train_epochs = 50\n",
    "args.patience = 30  # For early stopping\n",
    "\n",
    "args.use_amp = False  # whether to use automatic mixed precision training\n",
    "args.num_workers = 0\n",
    "args.itr = 1  # number of runs\n",
    "\n",
    "args.scale = True  # whether to scale to mean 0, var 1\n",
    "args.inverse = True  # whether to invert that scale before loss is calculated, lets keep this at False\n",
    "\n",
    "# This is for debugging to overfit\n",
    "# When True, patience doesn't matter at all and the model-state that is saved is the one after the last epoch\n",
    "# When False, the model-state that is saved is the one with the highest validation-loss and we can early stop with patience\n",
    "args.no_early_stop = False\n",
    "\n",
    "\n",
    "# Control data split from args, either a date string like \"2000-01-30\" or None (for default)\n",
    "args.date_start = \"2012-01-01\"  # Train data starts on this date, default is to go back as far as possible\n",
    "args.date_end = \"2020-01-01\"  # Train data starts on this date, default is to go back as far as possible\n",
    "args.date_test = \"2019-06-01\"  # Test data is data after this date, default is to use ~20% of the data as test data\n",
    "\n",
    "\n",
    "# args.load_model_path = \"stockformer_custom_ftMS_sl16_ll4_pl1_ei12_di12_co1_iFalse_dm512_nh8_el12_dl4_df2048_atfull_fc5_ebtimeF_dtFalse_mxFalse_pretrain_full_1h_0/checkpoint-pretrain.pth\"\n",
    "\n",
    "# Code to handle gpu\n",
    "# None to use all available GPUs\n",
    "# False for not using GPUs\n",
    "# 0 for using cuda:0\n",
    "# \"0,1\" for using both cuda:0 and cuda:1\n",
    "handle_gpu(args, None)\n",
    "\n",
    "# TODO: Figure out what this is for\n",
    "args.detail_freq = args.freq\n",
    "args.freq = args.freq[-1:]\n",
    "\n",
    "\n",
    "print(\"Args in experiment:\")\n",
    "print(args)\n",
    "Exp = Exp_Informer\n",
    "\n",
    "\n",
    "# # Generate config\n",
    "# import json\n",
    "# with open(\"configs/placeholder.json\", \"w\") as f:\n",
    "#     json.dump(args, f, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train & Test *args.itr* models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "928tzaA2AA2g",
    "outputId": "c19f673a-02d1-4f4d-91c3-d0f25e600443"
   },
   "outputs": [],
   "source": [
    "exp = None\n",
    "setting = None\n",
    "for ii in range(args.itr):\n",
    "    # setting record of experiments\n",
    "    setting = setting_from_args(args, ii)\n",
    "\n",
    "    # set experiments\n",
    "    exp = Exp(args)\n",
    "\n",
    "    # train\n",
    "    print(f\">>>>>>>start training : {setting}>>>>>>>>>>>>>>>>>>>>>>>>>>\")\n",
    "    exp.train(setting)\n",
    "\n",
    "    # test\n",
    "    print(f\">>>>>>>testing : {setting}<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\")\n",
    "    exp.test(setting, flag=\"test\", inverse=True)\n",
    "    exp.test(setting, flag=\"val\", inverse=True)\n",
    "    exp.test(setting, flag=\"train\", inverse=True)\n",
    "\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exp.test(setting, flag=\"test\")#, inverse=False)\n",
    "# exp.test(setting, flag=\"val\")#, inverse=False)\n",
    "# exp.test(setting, flag=\"train\")#, inverse=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CDHF-HerAE3u"
   },
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTkluNNcyMJt",
    "outputId": "780767fe-6321-4081-e827-6701daeb375b"
   },
   "outputs": [],
   "source": [
    "# If you already have a trained model, you can set the arguments and model path, then initialize a Experiment and use it to predict\n",
    "# Prediction is a sequence which is adjacent to the last date of the data, and does not exist in the data\n",
    "# If you want to get more information about prediction, you can refer to code `exp/exp_informer.py function predict()` and `data/data_loader.py class Dataset_Pred`\n",
    "\n",
    "manual = False\n",
    "\n",
    "if manual:\n",
    "    setting = \"stockformer_custom_ftMS_sl16_ll4_pl1_ei12_di12_co1_iFalse_dm512_nh8_el12_dl4_df2048_atfull_fc5_ebNone_dtFalse_mxFalse_full_1h_0\"\n",
    "    args = args_from_setting(setting, args)\n",
    "    exp = Exp(args)\n",
    "\n",
    "path = os.path.join(args.checkpoints, setting, \"checkpoint.pth\")\n",
    "\n",
    "exp.predict(setting, True)\n",
    "\n",
    "# the prediction will be saved in ./results/{setting}/real_prediction.npy\n",
    "prediction = np.load(f\"./results/{setting}/real_prediction.npy\")\n",
    "\n",
    "print(prediction.shape)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.plot(prediction[0,:,-1])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cNhEP_7sAgqC"
   },
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vMRk8VkQ2Iko",
    "outputId": "bbf3cd10-7294-472d-e330-21e00f20963a"
   },
   "outputs": [],
   "source": [
    "# When we finished exp.train(setting) and exp.test(setting), we will get a trained model and the results of test experiment\n",
    "# The results of test experiment will be saved in ./results/{setting}/pred.npy (prediction of test dataset) and ./results/{setting}/true.npy (groundtruth of test dataset)\n",
    "\n",
    "tp_dict = {}\n",
    "for flag in [\"train\", \"val\", \"test\"]:\n",
    "    preds_path = f\"./results/{setting}/pred_{flag}.npy\"\n",
    "    trues_path = f\"./results/{setting}/true_{flag}.npy\"\n",
    "    dates_path = f\"./results/{setting}/date_{flag}.npy\"\n",
    "    if (\n",
    "        os.path.exists(preds_path)\n",
    "        and os.path.exists(trues_path)\n",
    "        and os.path.exists(dates_path)\n",
    "    ):\n",
    "        tp_dict[flag] = (np.load(trues_path), np.load(preds_path), np.load(dates_path))\n",
    "        # tp_dict[flag] = list(zip(*sorted(zip(*tp_dict[flag]), key=lambda x: x[-1])))\n",
    "        s = np.argsort(tp_dict[flag][2], axis=None)\n",
    "        tp_dict[flag] = list(map(lambda x: x[s], tp_dict[flag]))\n",
    "\n",
    "\n",
    "print(\"Open true/pred data for:\", list(tp_dict.keys()))\n",
    "\n",
    "# [samples, pred_len, dimensions]\n",
    "print(\n",
    "    tp_dict[\"train\"][0].shape, tp_dict[\"val\"][0].shape, tp_dict[\"test\"][0].shape, \"\\n\\n\"\n",
    ")\n",
    "\n",
    "for flag in tp_dict:\n",
    "    trues, preds, dates = tp_dict[flag]\n",
    "    print(\n",
    "        f\"{flag}\\ttrues.shape: {trues.shape}, preds.shape: {preds.shape}, dates.shape: {preds.shape}\"\n",
    "    )\n",
    "\n",
    "    MSE = np.square(np.subtract(trues, preds)).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print(\"against preds\", MSE, RMSE)\n",
    "\n",
    "    MSE = np.square(np.subtract(trues, np.zeros(preds.shape))).mean()\n",
    "    RMSE = np.sqrt(MSE)\n",
    "    print(\"against 0s\", MSE, RMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "id": "kyPuOPGAAjl3",
    "outputId": "8554f6f8-c13a-43e1-b04b-5f27823445d0"
   },
   "outputs": [],
   "source": [
    "# draw OT prediction\n",
    "for flag in tp_dict:\n",
    "    trues, preds, dates = tp_dict[flag]\n",
    "    true = trues[:, 0, 0]\n",
    "    pred = preds[:, 0, 0]\n",
    "    date = dates[:, 0]\n",
    "    plt.figure(num=flag, figsize=(16, 4))\n",
    "    plt.title(flag)\n",
    "    plt.plot(date, true, label=\"GroundTruth\", linestyle=\"\", marker=\".\", markersize=4)\n",
    "    plt.plot(date, pred, label=\"Prediction\", linestyle=\"\", marker=\".\", markersize=4)\n",
    "    plt.plot(date, np.zeros(date.shape), color=\"red\")\n",
    "    # plt.scatter(range(trues.shape[0]), trues[:,0,0], marker='v', color='r', label='GroundTruth')\n",
    "    # plt.scatter(range(trues.shape[0]), preds[:,0,0], marker='^', color='m', label='Prediction')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(num=flag, figsize=(16, 4))\n",
    "    plt.title(\"Diff histogram\")\n",
    "    # plt.hist(np.abs(true), bins=len(true)//6, label='Diff 0', alpha=0.5)\n",
    "    # plt.hist(np.abs(true - pred), bins=len(true)//6, label='Diff Pred', alpha=0.5)\n",
    "    plt.hist(\n",
    "        [np.abs(true), np.abs(true - pred)], bins=60, label=[\"Diff 0\", \"Diff Pred\"]\n",
    "    )\n",
    "    plt.xlabel(\"Diff Value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    # df = pd.concat([pd.DataFrame(a, columns=[f\"{i}\"]) for i, a in enumerate([np.abs(true - pred), np.abs(true)])], axis=1)\n",
    "\n",
    "    # # plot the data\n",
    "    # df.plot.hist(stacked=True, bins=len(true), density=True, figsize=(10, 6), grid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic back-test based on buying in predicted direction if prediction is above a threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_tracker = (0, 0)\n",
    "\n",
    "# Tracks results\n",
    "tracker = {}\n",
    "\n",
    "df = read_data(os.path.join(args.root_path, args.data_path))\n",
    "\n",
    "# Get the percentile to check thresh until\n",
    "percentile = [50, 0.0]\n",
    "for flag in [\"train\"]:  # tp_dict:\n",
    "    _, preds, _ = tp_dict[flag]\n",
    "    percentile[1] += np.percentile(\n",
    "        np.abs(preds), percentile[0]\n",
    "    )  # np.median(np.abs(preds))\n",
    "percentile[1] /= len(tp_dict)\n",
    "print(f\"{percentile[0]}'th percentile: {percentile[1]}\")\n",
    "\n",
    "ticker, field = args.target.split(\"_\")\n",
    "assert field == \"pctchange\"\n",
    "\n",
    "for thresh in np.linspace(0, percentile[1], 501):\n",
    "    # print(\"thresh:\", thresh)\n",
    "    tracker[thresh] = {}\n",
    "    track = {}\n",
    "    for flag in tp_dict:\n",
    "        trues, preds, dates = tp_dict[flag]\n",
    "        # trues, preds = np.exp(trues), np.exp(preds)\n",
    "        true = trues[:, 0, 0]\n",
    "        pred = preds[:, 0, 0]\n",
    "        date = pd.DatetimeIndex(dates[:, 0], tz=\"UTC\")\n",
    "\n",
    "        \n",
    "\n",
    "        # Filter by thresh. Note in log scale\n",
    "        pred_f, true_f = apply_threshold_metric(pred, true, thresh)\n",
    "        df_f = df.loc[date[np.abs(pred) >= thresh]]\n",
    "\n",
    "        # Percent direction correct, ie up or down\n",
    "        pct_dir_correct = PctDirection.metric(pred, true)\n",
    "\n",
    "        # Percent profit all in\n",
    "        pct_profit_dir = PctProfitDirection.metric(pred_f, true_f, short_filter=0)\n",
    "        pct_profit_dir_nshort = PctProfitDirection.metric(pred_f, true_f, short_filter=1)\n",
    "        pct_profit_dir_oshort = PctProfitDirection.metric(pred_f, true_f, short_filter=2)\n",
    "\n",
    "        # Percent profit with tanh partial purchase\n",
    "        pct_profit_tanh = PctProfitTanh.metric(pred_f, true_f, short_filter=0)\n",
    "        pct_profit_tanh_nshort = PctProfitTanh.metric(pred_f, true_f, short_filter=1)\n",
    "        pct_profit_tanh_oshort = PctProfitTanh.metric(pred_f, true_f, short_filter=2)\n",
    "\n",
    "        # Optimal percent profit\n",
    "        pct_profit_dir_opt = PctProfitDirection.metric(true_f, true_f)\n",
    "\n",
    "        # Tune threshhold based off of train's metric we care about\n",
    "        tune_metric = pct_profit_tanh if args.loss == \"stock_tanh\" else pct_profit_dir\n",
    "        if tune_metric > max_tracker[0] and flag == \"train\":\n",
    "            max_tracker = (tune_metric, thresh)\n",
    "\n",
    "        # Save\n",
    "        tracker[thresh][flag] = {\n",
    "            \"pct_profit_dir\": pct_profit_dir,\n",
    "            \"pct_profit_dir_nshort\": pct_profit_dir_nshort,\n",
    "            \"pct_profit_dir_oshort\": pct_profit_dir_oshort,\n",
    "            \"pct_profit_tanh\": pct_profit_tanh,\n",
    "            \"pct_profit_tanh_nshort\": pct_profit_tanh_nshort,\n",
    "            \"pct_profit_tanh_oshort\": pct_profit_tanh_oshort,\n",
    "            \"pct_excluded\": (len(pred) - len(pred_f[pred_f > 0])) / len(pred),\n",
    "            \"pct_excluded_wshort\": (len(pred) - len(pred_f)) / len(pred),\n",
    "            \"pct_dir_correct\": pct_dir_correct,\n",
    "            \"pct_profit_dir_opt\": pct_profit_dir_opt,\n",
    "        }\n",
    "\n",
    "\n",
    "best_thresh = max_tracker[1]\n",
    "print(\"best thresh:\", best_thresh)\n",
    "for data_group in tracker[best_thresh]:\n",
    "    print(data_group, end=\"\\t\") \n",
    "    pprint(tracker[best_thresh][data_group], indent=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3,1, sharex=True, figsize=(16, 8))\n",
    "\n",
    "for flag in tp_dict:\n",
    "    trues, preds, dates = tp_dict[flag]\n",
    "    true = trues[:, 0, 0]\n",
    "    pred = preds[:, 0, 0]\n",
    "    date = pd.DatetimeIndex(dates[:, 0], tz=\"UTC\")\n",
    "\n",
    "    # Filter by best_thresh. Note in log scale\n",
    "    pred_f, true_f = apply_threshold_metric(pred, true, best_thresh)\n",
    "    date_f = date[np.abs(pred) >= best_thresh]\n",
    "\n",
    "    if \"lpp\" in args.loss:\n",
    "        metric = PctProfitDirection\n",
    "        metric_name = \"pct_profit_dir\"\n",
    "    elif \"tanh\" in args.loss:\n",
    "        metric = PctProfitTanh\n",
    "        metric_name = \"pct_profit_tanh\"\n",
    "\n",
    "\n",
    "\n",
    "    axs[0].plot(date_f, metric.accumulate(pred_f, true_f, short_filter=0), label=flag)\n",
    "    axs[0].set_ylabel(metric_name)\n",
    "    axs[0].set_title(metric_name)\n",
    "    axs[0].grid(axis = 'y')\n",
    "\n",
    "    axs[1].plot(date_f[pred_f > 0], metric.accumulate(pred_f, true_f, short_filter=1))#, label=flag)\n",
    "    axs[1].set_ylabel(f\"{metric_name}_nshort\")\n",
    "    axs[1].set_title(f\"{metric_name}_nshort\")\n",
    "    axs[1].grid(axis = 'y')\n",
    "\n",
    "    axs[2].plot(date_f[pred_f < 0], metric.accumulate(pred_f, true_f, short_filter=2))#, label=flag)\n",
    "    axs[2].set_ylabel(f\"{metric_name}_oshort\")\n",
    "    axs[2].set_title(f\"{metric_name}_oshort\")\n",
    "    axs[2].grid(axis = 'y')\n",
    "\n",
    "fig.legend()\n",
    "fig.suptitle(\"Cumulative metrics overtime\")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attention Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iflTTl0quCoK",
    "outputId": "3708fc91-517e-4c83-e133-059381bde271"
   },
   "outputs": [],
   "source": [
    "args.output_attention = True\n",
    "\n",
    "exp = Exp(args)\n",
    "\n",
    "model = exp.model\n",
    "\n",
    "path = os.path.join(args.checkpoints, setting, \"checkpoint.pth\")\n",
    "\n",
    "print(model.load_state_dict(torch.load(path)))\n",
    "\n",
    "df = pd.read_csv(os.path.join(args.root_path, args.data_path))\n",
    "df[args.cols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lDdzqm9HAk2C"
   },
   "outputs": [],
   "source": [
    "from data_provider.data_loader import Dataset_Custom\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "Data = Dataset_Custom\n",
    "timeenc = 0 if args.embed != \"timeF\" else 1\n",
    "flag = \"test\"\n",
    "shuffle_flag = False\n",
    "drop_last = True\n",
    "batch_size = 1\n",
    "data_set = Data(args, flag=flag)\n",
    "\n",
    "data_loader = DataLoader(\n",
    "    data_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=shuffle_flag,\n",
    "    num_workers=args.num_workers,\n",
    "    drop_last=drop_last,\n",
    ")\n",
    "\n",
    "\n",
    "idx = 0\n",
    "for i, (batch_x, batch_y, batch_x_mark, batch_y_mark, ds_index) in enumerate(\n",
    "    data_loader\n",
    "):\n",
    "    if i != idx:\n",
    "        continue\n",
    "    batch_x = batch_x.float().to(exp.device)\n",
    "    batch_y = batch_y.float()\n",
    "\n",
    "    batch_x_mark = batch_x_mark.float().to(exp.device)\n",
    "    batch_y_mark = batch_y_mark.float().to(exp.device)\n",
    "\n",
    "    dec_inp = torch.zeros_like(batch_y[:, -args.pred_len :, :]).float()\n",
    "    dec_inp = (\n",
    "        torch.cat([batch_y[:, : args.label_len, :], dec_inp], dim=1)\n",
    "        .float()\n",
    "        .to(exp.device)\n",
    "    )\n",
    "\n",
    "    outputs, attn = model(batch_x, batch_x_mark, dec_inp, batch_y_mark)\n",
    "\n",
    "\n",
    "print(attn[0].shape, attn[1].shape)  # , attn[2].shape\n",
    "\n",
    "\n",
    "layers = [0, 1]\n",
    "distil = \"Distil\" if args.distil else \"NoDistil\"\n",
    "for layer in layers:\n",
    "    print(\"\\n\\n==========================\")\n",
    "    print(\"Showing attention layer\", layer)\n",
    "    print(\"==========================\\n\\n\")\n",
    "    for h in range(0, args.n_heads):\n",
    "        plt.figure(figsize=[10, 8])\n",
    "        plt.title(f\"Informer, {distil}, attn:{args.attn} layer:{layer} head:{h}\")\n",
    "        A = attn[layer][0, h].detach().cpu().numpy()\n",
    "        ax = sns.heatmap(A, vmin=0, vmax=A.max() + 0.01)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "af42076dbd0dc4bad15096163af3221a89f84ba4155674ba19b5bb3ffd4e804c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
